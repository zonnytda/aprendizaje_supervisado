"""
M√≥dulo: predictor.py
Proyecto: Predicci√≥n Promedio Final - Egresados UNE
Clase: Predictor
Responsabilidad: Realizar predicciones en producci√≥n con modelos entrenados
Principio POO: Composici√≥n + Encapsulamiento
Autor: ZONNY
Fecha: Octubre 2025
"""

import numpy as np
import pandas as pd
import sys
from pathlib import Path
from typing import Dict, List, Optional, Tuple, Union, Any
import joblib
import json

# Agregar el directorio padre al path
sys.path.append(str(Path(__file__).resolve().parent.parent.parent))

from src.utils.helpers import (
    print_progress,
    print_section_header,
    validate_target_range
)

import warnings
warnings.filterwarnings('ignore')


class Predictor:
    """
    Realiza predicciones con modelos entrenados en entorno de producci√≥n.
    
    Caracter√≠sticas:
    - Carga modelos y transformadores persistidos
    - Valida y preprocesa inputs autom√°ticamente
    - Predicci√≥n √∫nica o por lotes (batch)
    - Intervalos de confianza estimados
    - Explicabilidad: contribuci√≥n de cada feature
    - Comparaci√≥n con promedios hist√≥ricos
    - Manejo robusto de errores
    
    Atributos:
        model: Modelo de ML cargado (Ridge/Lasso)
        feature_engineer: Ingeniero de features cargado
        feature_names (List[str]): Nombres de features esperados
        model_type (str): Tipo de modelo ('ridge' o 'lasso')
        is_ready (bool): Indica si est√° listo para predecir
        metadata (Dict): Informaci√≥n del modelo cargado
    
    Ejemplo de uso:
        >>> predictor = Predictor()
        >>> predictor.load_model('models/ridge_model.pkl')
        >>> predictor.load_transformers('models/')
        >>> 
        >>> input_data = {
        >>>     'FACULTAD': 'CIENCIAS',
        >>>     'PROGRAMA_ESTUDIOS': 'MATEM√ÅTICA',
        >>>     'NIVEL_ACADEMICO': 'PREGRADO',
        >>>     'SEXO': 'F',
        >>>     'CREDITOS_ACUMULADOS': 216,
        >>>     'ANNIO_EGRESO': 2024,
        >>>     'ANNIO_MATRICULA1': 2020,
        >>>     # ... m√°s features
        >>> }
        >>> 
        >>> resultado = predictor.predict_single(input_data)
        >>> print(f"Promedio predicho: {resultado['prediction']:.2f}")
        >>> print(f"Intervalo: [{resultado['lower_bound']:.2f}, {resultado['upper_bound']:.2f}]")
    """
    
    def __init__(self):
        """
        Inicializa el predictor.
        """
        self.model = None
        self.feature_engineer = None
        self.feature_names: List[str] = []
        self.model_type: Optional[str] = None
        self.is_ready: bool = False
        self.metadata: Dict = {}
        
        # Valores hist√≥ricos (para comparaci√≥n)
        self.historical_stats: Dict = {
            'mean': 15.96,
            'std': 1.15,
            'min': 12.23,
            'max': 19.30
        }
        
        print("‚úÖ Predictor inicializado")
        print("   Listo para cargar modelo y transformadores")
    
    def load_model(self, model_path: str) -> None:
        """
        Carga un modelo entrenado desde archivo.
        
        Args:
            model_path: Ruta del archivo .pkl con el modelo
        
        Raises:
            FileNotFoundError: Si el modelo no existe
        """
        model_path = Path(model_path)
        
        if not model_path.exists():
            raise FileNotFoundError(f"‚ùå Modelo no encontrado: {model_path}")
        
        print_progress(f"Cargando modelo desde {model_path.name}...", "üìÇ")
        
        try:
            # Cargar modelo completo
            model_data = joblib.load(model_path)
            
            self.model = model_data['model']
            self.model_type = model_data['model_type']
            self.metadata = model_data.get('metadata', {})
            self.feature_names = model_data.get('feature_names', [])
            
            print(f"‚úÖ Modelo cargado exitosamente")
            print(f"   Tipo: {self.model_type.upper()}")
            print(f"   Alpha: {self.model.alpha}")
            print(f"   Features: {len(self.model.coef_)}")
            
        except Exception as e:
            raise Exception(f"‚ùå Error al cargar modelo: {str(e)}")
    
    def load_transformers(self, path: str) -> None:
        """
        Carga transformadores de feature engineering.
        
        Args:
            path: Directorio con los transformadores
        """
        from src.features.feature_engineer import FeatureEngineer
        
        path = Path(path)
        
        print_progress("Cargando transformadores...", "üìÇ")
        
        try:
            # Crear instancia temporal de FeatureEngineer
            self.feature_engineer = FeatureEngineer(
                data=pd.DataFrame(),
                categorical_features=[],
                numerical_features=[]
            )
            
            # Cargar transformadores
            self.feature_engineer.load_transformers(str(path))
            
            # Actualizar feature names
            if self.feature_engineer.feature_names:
                self.feature_names = self.feature_engineer.feature_names
            
            print("‚úÖ Transformadores cargados exitosamente")
            
            # Verificar que est√° listo
            if self.model is not None and self.feature_engineer.is_fitted:
                self.is_ready = True
                print("‚úÖ Predictor listo para realizar predicciones")
            
        except Exception as e:
            print(f"‚ùå Error al cargar transformadores: {str(e)}")
            raise
    
    def validate_input(self, input_data: Dict) -> Tuple[bool, List[str]]:
        """
        Valida que el input tenga todas las features necesarias.
        
        Args:
            input_data: Diccionario con datos de entrada
        
        Returns:
            Tuple (es_v√°lido, lista_de_errores)
        """
        errors = []
        
        # Features categ√≥ricas requeridas
        required_categorical = [
            'FACULTAD', 'PROGRAMA_ESTUDIOS', 'SEDE', 
            'SEXO', 'NIVEL_ACADEMICO', 'DETALLE_TIPO_ESTUDIO'
        ]
        
        # Features num√©ricas requeridas
        required_numerical = [
            'ANNIO_EGRESO', 'CREDITOS_ACUMULADOS', 
            'ANNIO_MATRICULA1', 'ANNIO_SOLICITUD_TRAMITE', 
            'SEMESTRE_EGRESO'
        ]
        
        # Verificar categ√≥ricas
        for feature in required_categorical:
            if feature not in input_data:
                errors.append(f"Feature faltante: {feature}")
            elif input_data[feature] is None or input_data[feature] == '':
                errors.append(f"Feature vac√≠o: {feature}")
        
        # Verificar num√©ricas
        for feature in required_numerical:
            if feature not in input_data:
                errors.append(f"Feature faltante: {feature}")
            elif input_data[feature] is None:
                errors.append(f"Feature vac√≠o: {feature}")
            elif not isinstance(input_data[feature], (int, float)):
                errors.append(f"Feature {feature} debe ser num√©rico")
        
        # Validaciones de rango
        if 'ANNIO_EGRESO' in input_data:
            if input_data['ANNIO_EGRESO'] < 2020 or input_data['ANNIO_EGRESO'] > 2030:
                errors.append("ANNIO_EGRESO debe estar entre 2020 y 2030")
        
        if 'CREDITOS_ACUMULADOS' in input_data:
            if input_data['CREDITOS_ACUMULADOS'] < 0 or input_data['CREDITOS_ACUMULADOS'] > 300:
                errors.append("CREDITOS_ACUMULADOS debe estar entre 0 y 300")
        
        if 'ANNIO_MATRICULA1' in input_data and 'ANNIO_EGRESO' in input_data:
            if input_data['ANNIO_MATRICULA1'] > input_data['ANNIO_EGRESO']:
                errors.append("ANNIO_MATRICULA1 no puede ser mayor que ANNIO_EGRESO")
        
        is_valid = len(errors) == 0
        
        return is_valid, errors
    
    def _preprocess_input(self, input_data: Dict) -> np.ndarray:
        """
        Preprocesa input para predicci√≥n.
        
        Args:
            input_data: Diccionario con datos de entrada
        
        Returns:
            Array numpy procesado y listo para el modelo
        """
        # Convertir dict a DataFrame
        df = pd.DataFrame([input_data])
        
        # Aplicar transformaciones usando feature_engineer
        X_transformed = self.feature_engineer.transform(df)
        
        return X_transformed
    
    def predict_single(self, input_data: Dict, 
                      return_details: bool = True) -> Dict:
        """
        Realiza predicci√≥n para una sola instancia.
        
        Args:
            input_data: Diccionario con features de entrada
            return_details: Si retornar detalles adicionales
        
        Returns:
            Diccionario con predicci√≥n y detalles
        
        Raises:
            ValueError: Si el predictor no est√° listo o input es inv√°lido
        """
        if not self.is_ready:
            raise ValueError(
                "‚ùå Predictor no est√° listo. "
                "Ejecuta load_model() y load_transformers() primero."
            )
        
        # Validar input
        is_valid, errors = self.validate_input(input_data)
        if not is_valid:
            raise ValueError(f"‚ùå Input inv√°lido:\n" + "\n".join(f"  ‚Ä¢ {e}" for e in errors))
        
        try:
            # Preprocesar
            X = self._preprocess_input(input_data)
            
            # Predecir
            prediction = self.model.predict(X)[0]
            
            # Asegurar que est√° en rango v√°lido
            prediction = np.clip(prediction, self.historical_stats['min'], 
                               self.historical_stats['max'])
            
            result = {
                'prediction': float(prediction),
                'input': input_data
            }
            
            # Agregar detalles si se solicita
            if return_details:
                # Intervalo de confianza (estimado usando std del modelo)
                std_error = self.historical_stats['std'] * 0.5  # Aproximaci√≥n
                result['lower_bound'] = float(max(prediction - 1.96 * std_error, 
                                                 self.historical_stats['min']))
                result['upper_bound'] = float(min(prediction + 1.96 * std_error, 
                                                 self.historical_stats['max']))
                result['confidence_interval'] = '95%'
                
                # Comparaci√≥n con promedio hist√≥rico
                diff_from_mean = prediction - self.historical_stats['mean']
                result['comparison'] = {
                    'historical_mean': self.historical_stats['mean'],
                    'difference': float(diff_from_mean),
                    'percentile': float(self._calculate_percentile(prediction)),
                    'interpretation': self._get_interpretation(prediction)
                }
                
                # Metadata del modelo
                result['model_info'] = {
                    'type': self.model_type,
                    'alpha': float(self.model.alpha)
                }
            
            return result
            
        except Exception as e:
            raise Exception(f"‚ùå Error durante la predicci√≥n: {str(e)}")
    
    def predict_batch(self, input_df: pd.DataFrame) -> pd.DataFrame:
        """
        Realiza predicciones para m√∫ltiples instancias.
        
        Args:
            input_df: DataFrame con m√∫ltiples instancias
        
        Returns:
            DataFrame con predicciones agregadas
        """
        if not self.is_ready:
            raise ValueError(
                "‚ùå Predictor no est√° listo. "
                "Ejecuta load_model() y load_transformers() primero."
            )
        
        print_progress(f"Realizando predicciones batch ({len(input_df)} instancias)...", "üîÆ")
        
        try:
            # Preprocesar todas las instancias
            X = self.feature_engineer.transform(input_df)
            
            # Predecir
            predictions = self.model.predict(X)
            
            # Asegurar rango v√°lido
            predictions = np.clip(predictions, 
                                self.historical_stats['min'], 
                                self.historical_stats['max'])
            
            # Crear DataFrame de resultados
            results_df = input_df.copy()
            results_df['PROMEDIO_PREDICHO'] = predictions
            
            # Agregar intervalos de confianza
            std_error = self.historical_stats['std'] * 0.5
            results_df['LIMITE_INFERIOR'] = np.maximum(
                predictions - 1.96 * std_error, 
                self.historical_stats['min']
            )
            results_df['LIMITE_SUPERIOR'] = np.minimum(
                predictions + 1.96 * std_error, 
                self.historical_stats['max']
            )
            
            print(f"‚úÖ Predicciones completadas")
            print(f"   Promedio predicho: {predictions.mean():.2f}")
            print(f"   Rango: [{predictions.min():.2f}, {predictions.max():.2f}]")
            
            return results_df
            
        except Exception as e:
            raise Exception(f"‚ùå Error durante predicci√≥n batch: {str(e)}")
    
    def get_feature_contribution(self, input_data: Dict, 
                                 top_n: int = 10) -> Dict:
        """
        Calcula la contribuci√≥n de cada feature a la predicci√≥n.
        
        Args:
            input_data: Diccionario con features de entrada
            top_n: N√∫mero de features top a retornar
        
        Returns:
            Diccionario con contribuciones de features
        """
        if not self.is_ready:
            raise ValueError("‚ùå Predictor no est√° listo")
        
        try:
            # Preprocesar
            X = self._preprocess_input(input_data)
            
            # Obtener coeficientes del modelo
            coefs = self.model.coef_
            
            # Calcular contribuciones (coef * valor)
            contributions = X[0] * coefs
            
            # Crear DataFrame con contribuciones
            contrib_df = pd.DataFrame({
                'feature': self.feature_names[:len(contributions)],
                'value': X[0],
                'coefficient': coefs,
                'contribution': contributions,
                'abs_contribution': np.abs(contributions)
            })
            
            # Ordenar por contribuci√≥n absoluta
            contrib_df = contrib_df.sort_values('abs_contribution', ascending=False)
            
            # Top N
            top_features = contrib_df.head(top_n)
            
            result = {
                'intercept': float(self.model.intercept_),
                'top_features': top_features.to_dict('records'),
                'total_contribution': float(contributions.sum()),
                'prediction': float(self.model.intercept_ + contributions.sum())
            }
            
            return result
            
        except Exception as e:
            raise Exception(f"‚ùå Error al calcular contribuciones: {str(e)}")
    
    def predict_with_explanation(self, input_data: Dict) -> Dict:
        """
        Predicci√≥n completa con explicaci√≥n detallada.
        
        Args:
            input_data: Diccionario con features de entrada
        
        Returns:
            Diccionario con predicci√≥n y explicaci√≥n completa
        """
        # Predicci√≥n b√°sica
        result = self.predict_single(input_data, return_details=True)
        
        # Agregar contribuciones de features
        contributions = self.get_feature_contribution(input_data, top_n=10)
        result['feature_contributions'] = contributions
        
        # Agregar interpretaci√≥n detallada
        result['detailed_explanation'] = self._generate_explanation(
            result['prediction'],
            contributions,
            input_data
        )
        
        return result
    
    def _calculate_percentile(self, value: float) -> float:
        """
        Calcula en qu√© percentil est√° el valor predicho.
        
        Args:
            value: Valor predicho
        
        Returns:
            Percentil (0-100)
        """
        from scipy import stats
        
        # Asumiendo distribuci√≥n normal con stats hist√≥ricos
        percentile = stats.norm.cdf(
            value, 
            loc=self.historical_stats['mean'], 
            scale=self.historical_stats['std']
        ) * 100
        
        return percentile
    
    def _get_interpretation(self, prediction: float) -> str:
        """
        Genera interpretaci√≥n textual de la predicci√≥n.
        
        Args:
            prediction: Valor predicho
        
        Returns:
            String con interpretaci√≥n
        """
        mean = self.historical_stats['mean']
        std = self.historical_stats['std']
        
        if prediction >= mean + std:
            return "Excelente - Por encima del promedio hist√≥rico"
        elif prediction >= mean:
            return "Bueno - Por encima del promedio"
        elif prediction >= mean - std:
            return "Regular - Cerca del promedio"
        else:
            return "Bajo - Por debajo del promedio hist√≥rico"
    
    def _generate_explanation(self, prediction: float, 
                             contributions: Dict, 
                             input_data: Dict) -> str:
        """
        Genera explicaci√≥n en lenguaje natural.
        
        Args:
            prediction: Valor predicho
            contributions: Contribuciones de features
            input_data: Datos de entrada
        
        Returns:
            String con explicaci√≥n detallada
        """
        explanation = f"Predicci√≥n: {prediction:.2f} puntos\n\n"
        
        explanation += "Factores principales que influyeron:\n"
        
        top_3 = contributions['top_features'][:3]
        for i, feat in enumerate(top_3, 1):
            impact = "positivamente" if feat['contribution'] > 0 else "negativamente"
            explanation += f"{i}. {feat['feature']}: influy√≥ {impact} "
            explanation += f"(contribuci√≥n: {feat['contribution']:.4f})\n"
        
        explanation += f"\nComparaci√≥n:\n"
        explanation += f"‚Ä¢ Promedio hist√≥rico UNE: {self.historical_stats['mean']:.2f}\n"
        diff = prediction - self.historical_stats['mean']
        explanation += f"‚Ä¢ Tu predicci√≥n est√° {abs(diff):.2f} puntos "
        explanation += "por encima" if diff > 0 else "por debajo"
        explanation += " del promedio\n"
        
        return explanation
    
    def set_historical_stats(self, stats: Dict) -> None:
        """
        Actualiza estad√≠sticas hist√≥ricas para comparaci√≥n.
        
        Args:
            stats: Diccionario con estad√≠sticas (mean, std, min, max)
        """
        self.historical_stats.update(stats)
        print(f"‚úÖ Estad√≠sticas hist√≥ricas actualizadas")
    
    def get_model_info(self) -> Dict:
        """
        Obtiene informaci√≥n completa del predictor.
        
        Returns:
            Diccionario con informaci√≥n del modelo
        """
        info = {
            'is_ready': self.is_ready,
            'model_type': self.model_type,
            'n_features': len(self.feature_names) if self.feature_names else 0,
            'metadata': self.metadata,
            'historical_stats': self.historical_stats,
        }
        
        if self.model is not None:
            info['model_params'] = {
                'alpha': float(self.model.alpha),
                'intercept': float(self.model.intercept_)
            }
        
        return info
    
    def __repr__(self) -> str:
        """Representaci√≥n string del objeto"""
        status = "ready" if self.is_ready else "not ready"
        return f"Predictor(model={self.model_type}, {status})"


# ============================================
# EJEMPLO DE USO
# ============================================

if __name__ == "__main__":
    """
    Ejemplo de uso completo de Predictor
    """
    print_section_header("üß™ TESTING PREDICTOR CLASS")
    
    # Nota: Este ejemplo requiere modelos ya entrenados
    # Para probarlo realmente, primero entrena y guarda un modelo
    
    print("üìù Ejemplo de uso del Predictor:\n")
    
    print("# 1. Inicializar predictor")
    print("predictor = Predictor()\n")
    
    print("# 2. Cargar modelo y transformadores")
    print("predictor.load_model('models/ridge_model.pkl')")
    print("predictor.load_transformers('models/')\n")
    
    print("# 3. Preparar datos de entrada")
    print("input_data = {")
    print("    'FACULTAD': 'CIENCIAS',")
    print("    'PROGRAMA_ESTUDIOS': 'MATEM√ÅTICA E INFORM√ÅTICA',")
    print("    'NIVEL_ACADEMICO': 'PREGRADO',")
    print("    'SEDE': 'LA MOLINA',")
    print("    'SEXO': 'F',")
    print("    'DETALLE_TIPO_ESTUDIO': 'REGULAR',")
    print("    'ANNIO_EGRESO': 2024,")
    print("    'SEMESTRE_EGRESO': 20241,")
    print("    'CREDITOS_ACUMULADOS': 216,")
    print("    'ANNIO_MATRICULA1': 2020,")
    print("    'ANNIO_SOLICITUD_TRAMITE': 2024,")
    print("}\n")
    
    print("# 4. Realizar predicci√≥n")
    print("resultado = predictor.predict_single(input_data)\n")
    
    print("# 5. Ver resultados")
    print("print(f\"Promedio predicho: {resultado['prediction']:.2f}\")")
    print("print(f\"Intervalo 95%: [{resultado['lower_bound']:.2f}, {resultado['upper_bound']:.2f}]\")")
    print("print(f\"Interpretaci√≥n: {resultado['comparison']['interpretation']}\")\n")
    
    print("# 6. Predicci√≥n con explicaci√≥n")
    print("resultado_explicado = predictor.predict_with_explanation(input_data)")
    print("print(resultado_explicado['detailed_explanation'])\n")
    
    print("# 7. Predicci√≥n por lotes")
    print("df_batch = pd.DataFrame([input_data1, input_data2, input_data3])")
    print("resultados_batch = predictor.predict_batch(df_batch)")
    print("print(resultados_batch[['FACULTAD', 'PROMEDIO_PREDICHO']])\n")
    
    print("‚úÖ Ejemplo de uso completado")
    print("\nüí° Para usar realmente el Predictor:")
    print("   1. Entrena un modelo con ModelTrainer")
    print("   2. Guarda el modelo con save_model()")
    print("   3. Guarda los transformadores con FeatureEngineer.save_transformers()")
    print("   4. Luego usa Predictor para hacer predicciones en producci√≥n")